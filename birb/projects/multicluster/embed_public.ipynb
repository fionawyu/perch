{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU3pUl3cT5sq"
      },
      "source": [
        "# Small-Model Training\n",
        "\n",
        "Train a small linear model over fixed embeddings, using a curated set of training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrCu2iSQoIHs"
      },
      "source": [
        "# Imports and Configuration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhOcIEtYG6uL"
      },
      "outputs": [],
      "source": [
        "#@title Imports. { vertical-output: true }\n",
        "\n",
        "# Global imports\n",
        "import collections\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from etils import epath\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "\n",
        "use_tf_gpu = True #@param\n",
        "if not use_tf_gpu:\n",
        "  tf.config.experimental.set_visible_devices([], \"GPU\")\n",
        "\n",
        "# Chirp imports\n",
        "from chirp import audio_utils\n",
        "from chirp import path_utils\n",
        "from chirp.preprocessing import pipeline\n",
        "from chirp.models import frontend\n",
        "from chirp.models import metrics\n",
        "from chirp.inference import models\n",
        "from chirp.inference import tf_examples\n",
        "from chirp.projects.multicluster import classify\n",
        "from chirp.projects.multicluster import data_lib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCfIqyIyh5wU"
      },
      "outputs": [],
      "source": [
        "#@title Configure data locations and load model. { vertical-output: true }\n",
        "\n",
        "# Path to TFRecords of unlabeled embeddings.\n",
        "unlabeled_embeddings_path = '' #@param\n",
        "embeddings_glob = epath.Path(unlabeled_embeddings_path) / '*'\n",
        "\n",
        "# Hop-size used when creating the embeddings dataset.\n",
        "embedding_hop_size_s = 5.0 #@param\n",
        "# Number of folder name levels in embedding file id's.\n",
        "file_id_depth = 1 #@param\n",
        "\n",
        "# Globs for source audio files represented in the unlabeled embeddings.\n",
        "# e.g., /data/project_audio/*/*.wav\n",
        "audio_globs = [] #@param\n",
        "\n",
        "# Path to the labeled wav data.\n",
        "# Should be in 'folder-of-folders' format - a folder with sub-folders for\n",
        "# each class of interest.\n",
        "# Audio in sub-folders should be wav files.\n",
        "# Audio should ideally be 5s audio clips, but the system is quite forgiving.\n",
        "labeled_data_path = '' #@param\n",
        "\n",
        "model_choice = 'perch' #@param['perch', 'birdnet']\n",
        "# Path to the folder contianing the perch model, which you can get at:\n",
        "# https://tfhub.dev/google/bird-vocalization-classifier\n",
        "perch_path = '' #@param\n",
        "# Path to a local copy of a BirdNet TFLite file.\n",
        "birdnet_path = '' #@param\n",
        "\n",
        "# Create the config and load the model given the provided information.\n",
        "if model_choice == 'perch':\n",
        "  model_key='taxonomy_model_tf'\n",
        "  model_config = {\n",
        "      'model_path': perch_path, \n",
        "      'window_size_s': 5.0, \n",
        "      'hop_size_s': embedding_hop_size_s, \n",
        "      'sample_rate': 32000\n",
        "  }\n",
        "elif model_choice == 'birdnet':\n",
        "  model_key='birdnet'\n",
        "  model_config = {\n",
        "      'window_size_s': 3.0, \n",
        "      'hop_size_s': embedding_hop_size_s,\n",
        "      'sample_rate': 48000,\n",
        "  } \n",
        "else:\n",
        "  raise ValueError(f'unknown model choice {model_choice=}')\n",
        "\n",
        "config = bootstrap.BootstrapConfig(\n",
        "    # Path to pre-generated embeddings TFRecord files.\n",
        "    embeddings_glob=embeddings_glob,\n",
        "    embedding_hop_size_s=embedding_hop_size_s,\n",
        "    file_id_depth=file_id_depth,\n",
        "    # Globs for audio files represented in the embeddings.\n",
        "    audio_globs=audio_globs,\n",
        "\n",
        "    # Path for storing annotated examples.\n",
        "    annotated_path=labeled_data_path,\n",
        "\n",
        "    # Embedding model info.\n",
        "    # Needs to match the model used for the embeddings DB, of course...\n",
        "    model_key=model_key,\n",
        "    model_config=model_config)\n",
        "project_state = bootstrap.BootstrapState(config)\n",
        "embedding_model = project_state.embedding_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waSrbkzHl2o3"
      },
      "source": [
        "# Supervised Learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ye4YRiARHHeR"
      },
      "outputs": [],
      "source": [
        "#@title Load+Embed the Labeled Dataset. { vertical-output: true }\n",
        "\n",
        "# Time-pooling strategy for examples longer than the model's window size.\n",
        "time_pooling = 'mean' #@param\n",
        "\n",
        "merged = data_lib.MergedDataset(config.annotated_path, \n",
        "                                embedding_model, \n",
        "                                time_pooling=time_pooling)\n",
        "\n",
        "# Label distribution\n",
        "lbl_counts = np.sum(merged.data['label_hot'], axis=0)\n",
        "print('num classes :', (lbl_counts \u003e 0).sum())\n",
        "print('mean ex / class :', lbl_counts.sum() / (lbl_counts \u003e 0).sum())\n",
        "print('min ex / class :', (lbl_counts + (lbl_counts == 0) * 1e6).min())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMzrwSzURe1i"
      },
      "outputs": [],
      "source": [
        "#@title Train linear model over embeddings. { vertical-output: true }\n",
        "\n",
        "# Number of random training examples to choose form each class.\n",
        "example_per_class = 128 #@param\n",
        "\n",
        "# Number of random re-trainings. Allows judging model stability.\n",
        "num_seeds = 1 #@param\n",
        "\n",
        "# Classifier training hyperparams.\n",
        "# These should be good defaults.\n",
        "batch_size = 32\n",
        "num_epochs = 128\n",
        "num_hiddens = -1\n",
        "learning_rate = 1e-3\n",
        "\n",
        "metrics = collections.defaultdict(list)\n",
        "for seed in range(num_seeds):\n",
        "  if num_hiddens \u003e 0:\n",
        "    model = classify.get_two_layer_model(\n",
        "        num_hiddens, merged.embedding_dim, merged.num_classes)\n",
        "  else:\n",
        "    model = classify.get_linear_model(\n",
        "        merged.embedding_dim, merged.num_classes)\n",
        "  run_metrics = classify.train_embedding_model(\n",
        "      model, merged, example_per_class, num_epochs, seed, batch_size, learning_rate)\n",
        "  metrics['acc'].append(run_metrics.top1_accuracy)\n",
        "  metrics['auc_roc'].append(run_metrics.auc_roc)\n",
        "  metrics['cmap'].append(run_metrics.cmap_value)\n",
        "  metrics['maps'].append(run_metrics.class_maps)\n",
        "  metrics['recall'].append(run_metrics.recall)\n",
        "mean_acc = np.mean(metrics['acc'])\n",
        "mean_auc_roc = np.mean(metrics['auc_roc'])\n",
        "mean_cmap = np.mean(metrics['cmap'])\n",
        "mean_recall = np.mean(metrics['recall'])\n",
        "print(f'{example_per_class:d},  acc:{mean_acc:5.2f},  '\n",
        "      f'auc_roc:{mean_auc_roc:5.2f},  cmap:{mean_cmap:5.2f},  '\n",
        "      f'recall:{mean_recall:5.2f}')\n",
        "for lbl, auc in zip(merged.labels, run_metrics.class_maps):\n",
        "  if np.isnan(auc):\n",
        "    continue\n",
        "  print(f'{lbl:8s}, auc_roc:{auc:5.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBjsS_8xh6IB"
      },
      "source": [
        "# Evaluation on Unlabeled Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-Sxvh0JCCRW"
      },
      "outputs": [],
      "source": [
        "#@title Run model on target unlabeled data. { vertical-output: true }\n",
        "\n",
        "# Choose the target class to work with.\n",
        "target_class = '' #@param\n",
        "# Choose a target logit; will display results close to the target.\n",
        "target_logit = 2.0 #@param\n",
        "# Number of results to display.\n",
        "num_results = 25 #@param\n",
        "\n",
        "# Create the embeddings dataset.\n",
        "embeddings_ds = tf_examples.create_embeddings_dataset(unlabeled_embeddings_path)\n",
        "target_class_idx = merged.labels.index(target_class)\n",
        "results, all_logits = search.classifer_search_embeddings_parallel(\n",
        "    embeddings_ds, model, target_class_idx, hop_size_s=5.0,\n",
        "    target_logit=target_logit, top_k=num_results\n",
        ")\n",
        "\n",
        "# Plot the histogram of logits.\n",
        "_, ys, _ = plt.hist(all_logits, bins=128, density=True)\n",
        "plt.xlabel(f'{target_class} logit')\n",
        "plt.ylabel(f'density')\n",
        "plt.plot([target_logit, target_logit], [0.0, np.max(ys)], 'r:')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCGcfWxiEL4m"
      },
      "outputs": [],
      "source": [
        "#@title Display results for the target label. { vertical-output: true }\n",
        "\n",
        "display_labels = merged.labels\n",
        "\n",
        "extra_labels = [] #@param\n",
        "for label in extra_labels:\n",
        "  if label not in merged.labels:\n",
        "    display_labels += (label,)\n",
        "if 'unknown' not in merged.labels:\n",
        "  display_labels += ('unknown',)\n",
        "\n",
        "display.display_search_results(\n",
        "    results, embedding_model.sample_rate, \n",
        "    project_state.source_map, \n",
        "    checkbox_labels=display_labels,\n",
        "    max_workers=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JR4jUZKvatdK"
      },
      "outputs": [],
      "source": [
        "#@title Add selected results to the labeled data. { vertical-output: true }\n",
        "\n",
        "results.write_labeled_data(\n",
        "    config.annotated_path, embedding_model.sample_rate)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "",
        "kind": "local"
      },
      "name": "embed_notebook.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1H3mI6aJb42ANqjc7tz5ROr2WAHaORcJ5",
          "timestamp": 1684963703948
        },
        {
          "file_id": "16odjhAZX3EjnHNUPU6W963rUf_0yzLjx",
          "timestamp": 1684269881959
        }
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
